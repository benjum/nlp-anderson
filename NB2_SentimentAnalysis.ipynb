{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a548d39-6f15-4dc0-af4a-8d22d5caad0b",
   "metadata": {},
   "source": [
    "# Sentiment Analysis\n",
    "Method #1 -> use established dictionaries of sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc531a9-6f62-4529-a543-77748b21f0e6",
   "metadata": {},
   "source": [
    "Acknowledgements:\n",
    "* https://peerchristensen.netlify.app/post/fair-is-foul-and-foul-is-fair-a-tidytext-entiment-analysis-of-shakespeare-s-tragedies/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "254fe281-378f-43cc-bfc5-df86dc480ffb",
   "metadata": {},
   "source": [
    "We'll look at the evolution of sentiment in Shakespeare's plays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14938694-5bed-4052-9688-5eb365649a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "library('gutenbergr')\n",
    "library(tidyverse)\n",
    "\n",
    "# Needed for sentiment collection\n",
    "library(tidytext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7170c6-7530-431e-b2ae-255e58fd2065",
   "metadata": {},
   "outputs": [],
   "source": [
    "shakespeare <- gutenberg_works(author == \"Shakespeare, William\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde6dd84-218d-4712-bcf6-2f74a22891dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "head(shakespeare)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2570e0-a437-4cad-a0c0-4bacf597c01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "IDs = shakespeare[c(16,24,34,35,54,55,56,57,58,59),]$gutenberg_id\n",
    "shakespeare %>% filter(gutenberg_id %in% IDs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee024054-1450-4cb8-b679-22d57b7978d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plays = gutenberg_download(IDs,meta_fields = \"title\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1fdcfdf-847d-41bb-baa6-d9ebd906cb8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f918bb4f-c2b4-41ba-bf75-ac10182e7fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_sentiments('bing')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558ca7df-4884-4db0-b9f9-e06ebe8281c8",
   "metadata": {},
   "source": [
    "Tidytext also has its own set of NLP tools that one can use.  For example, here we use it for word tokenization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5eac38-b59d-40f0-92d9-a3d355b0449d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plays %>% \n",
    "group_by(title) %>% \n",
    "unnest_tokens(word, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa07a98-08ea-4e84-9ad2-7e012797fb1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plays %>% \n",
    "group_by(title) %>% \n",
    "unnest_tokens(word, text) %>% \n",
    "inner_join(get_sentiments(\"bing\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc7c3754-2af0-4cb2-8c91-b0784478396e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiments <- plays %>% \n",
    "                group_by(title) %>% \n",
    "                unnest_tokens(word, text) %>% \n",
    "                inner_join(get_sentiments(\"bing\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7dce950-9fe1-4c60-911f-07773e6ff4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiments %>% group_by(title) %>% count(sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b0f99b-c591-4bf7-95bc-d2c0874ecc08",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiments %>% group_by(title) %>% count(sentiment) %>%\n",
    " ggplot(aes(x = sentiment, y = n, fill = title)) + \n",
    " geom_bar(stat = \"identity\") +\n",
    " facet_wrap(~title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60754539-e34a-4850-8909-08e941eb33df",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiments <- plays            %>% \n",
    "  group_by(title)             %>%\n",
    "  unnest_tokens(word, text)   %>%      # tokenize words\n",
    "  #anti_join(stop_words) %>%           # in case we would like to remove stop words\n",
    "  inner_join(get_sentiments(\"bing\"))   # keep only words found in the Bing lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e48166-a71d-4d59-abae-25e970bf58f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3756cbc9-8869-4afa-b115-81ae26bcaf4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiments <- mutate(sentiments, line = row_number())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab7b473-262a-44e5-a1a1-5e9fe5ed5605",
   "metadata": {},
   "outputs": [],
   "source": [
    "plays            %>% \n",
    "  group_by(title)             %>%\n",
    "  unnest_tokens(word, text) %>%\n",
    "  inner_join(get_sentiments(\"bing\")) %>%\n",
    "  mutate(line = row_number()) %>%\n",
    "  count(title, index = line %/% 100, sentiment) %>%  \n",
    "  spread(sentiment, n, fill = 0)                %>%                 \n",
    "  mutate(sentiment = positive - negative)       %>%\n",
    "  ggplot(aes(index, sentiment, fill = sentiment)) +\n",
    "  geom_col(show.legend = FALSE) +\n",
    "  facet_wrap(~title,scales = \"free_x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d0f13b-ca9a-4599-acea-9d1f3f431561",
   "metadata": {},
   "source": [
    "## Method #2 for Sentiment Analysis\n",
    "Supervised Machine Learning with Naives Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c91662cd-be3d-415c-a0af-15180d996c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "library(quanteda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae19a7e-d277-4d5c-93b2-e758ba416bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt <- c(d1 = \"Best Good Best\",\n",
    "         d2 = \"Best Best Ok\",\n",
    "         d3 = \"Best Blah\",\n",
    "         d4 = \"Bad Worst Best\",\n",
    "         d5 = \"Best Best Best Bad Worst\")\n",
    "txt <- tokens(txt)\n",
    "trainingset <- dfm(txt, tolower = FALSE)\n",
    "trainingclass <- factor(c(\"Y\", \"Y\", \"Y\", \"N\", NA), ordered = TRUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0f3fb6-28fa-4273-bbb7-6110ef875b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e90ed9cc-cbce-4c21-a54e-7281d4d52b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingclass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a4763a-af62-4a90-95f0-9a80f6ca9709",
   "metadata": {},
   "source": [
    "Classification with Naive Bayes.\n",
    "\n",
    "We take Bayes theorem:\n",
    "\n",
    "$$P(c|F) = \\frac{P(F|c)P(c)}{P(F)}$$\n",
    "\n",
    "with the (sometimes unreasonable but also unreasonably effective) assumption that:\n",
    "\n",
    "$$P(F|c)P(c) = P(f_1|c)P(f_2|c)...P(f_n|c)P(c)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d66369b5-980a-4a1a-8a17-57bd842f4ecb",
   "metadata": {},
   "source": [
    "For Quanteda's Naive Bayes classifier, need quanteda.textmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5747e6-bc68-4c53-863d-6bfc6b74253b",
   "metadata": {},
   "outputs": [],
   "source": [
    "library('quanteda.textmodels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04bd8321-c325-4b96-b89a-f02cfafa84eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "(tmod1 <- textmodel_nb(x = trainingset, y = trainingclass, prior = \"docfreq\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e4ed5d-37c4-4a7b-a6d1-4a33c8b43600",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(tmod1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39ae492-03a1-4b53-bc75-eaeceb831413",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb179dfe-4505-448e-a4d6-a97096c78c28",
   "metadata": {},
   "source": [
    "Example for `Best`:\n",
    "\n",
    "* Y for d1,d2,d3\n",
    "* N for d4\n",
    "* P(Best|Y) = (2+2+1) / (3+3+2) = 5/8 = 0.625\n",
    "* P(Best|N) = (1) / (3) = 0.333\n",
    "\n",
    "?\n",
    "\n",
    "* There is the danger of having 0's for probabilities -> this is taken care of by add-one or Laplace smoothing (effectively as if every term occurs at least once):\n",
    "  * P(Best|Y) = (5 + 1) / (8 + 6), where the top +1 comes from adding one per term and the bottom +6 comes from adding one for all terms (6 unique terms)\n",
    "  * P(Best|Y) = 6/14 = 0.42857...\n",
    "  * P(Best|N) = (1+1) / (3+6) = 2/9 = 0.222..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06800c68-4c87-4a9a-93e4-41d45b809cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "coef(tmod1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04434236-aaf2-436b-aeb4-847d391366a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(tmod1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32a4f77-a225-45b5-adf5-122e4c983d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(tmod1, type = \"prob\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68d6693-a3db-4c00-ab7a-785078513898",
   "metadata": {},
   "outputs": [],
   "source": [
    "# contrast with other priors\n",
    "predict(textmodel_nb(trainingset, trainingclass, prior = \"uniform\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde8e934-1192-41a8-b078-af7c4ee0c66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(textmodel_nb(trainingset, trainingclass, prior = \"termfreq\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6bb6eef-7c18-43b1-b88f-3a2f70481eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmod2 <- textmodel_nb(trainingset, trainingclass, distribution = \"Bernoulli\", prior = \"docfreq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86856e5-7507-4cad-bed5-c207b75f82fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "coef(tmod2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd7d096-c64a-471c-b69c-bbf49e858b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a417d7ed-1104-4087-b4c5-f019f9b65c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfm_weight(trainingset, scheme=\"boolean\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2813c50b-1e71-43e9-8b29-55a4f68852aa",
   "metadata": {},
   "source": [
    "The probabilities now are the fraction of documents of class Y that contain the term Best:\n",
    "* P(Best|Y) = [(1+1+1) + 1] / [(1+1+1) + 2] = 4/5 = 0.8\n",
    "* P(Best|N) = [(1) + 1] / [(1) + 2] = 2/3 = 0.667"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b91f5f74-83d7-4460-9d8b-f923a9b1af3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(tmod2, newdata = trainingset[5, ], type = \"prob\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "493f3dd1-4481-4028-b1c8-ce314e80861d",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(tmod2, newdata = trainingset[5, ])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.2.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
